"""
ì¸ë¼ì¸ í…ŒìŠ¤íŠ¸ - ì´ë¯¸ì§€ URL ë˜ëŠ” base64ë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ íë¦„:
1. ì´ë¯¸ì§€ ë¶„ì„ + ì§ˆë¬¸ ì¦ê°• + Gate íŒë‹¨
2. KB ê²€ìƒ‰ (ìœ ì‚¬ ì¦ìƒ ë§¤ì¹­)
3. Perplexity ê²€ìƒ‰ (ì–¸ì–´ë³„, KB ê²°ê³¼ í™œìš©)
4. êµ¬ì¡°í™” í¸ì§‘
"""
import asyncio
import base64
import json
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from gcode_analyzer.troubleshoot.image_analyzer import ImageAnalyzer
from gcode_analyzer.troubleshoot.perplexity_searcher import PerplexitySearcher
from gcode_analyzer.troubleshoot.structured_editor import StructuredEditor
from gcode_analyzer.troubleshoot.models import UserPlan, ProblemType, SearchDecision, PerplexitySearchResult
from gcode_analyzer.troubleshoot.kb import search_kb


async def test_with_image_bytes(image_bytes: bytes, symptom_text: str = "í˜„ì¬ì¦ìƒë­ì•¼? ì–´ë–»ê²Œí•´ì•¼í•´"):
    """ì´ë¯¸ì§€ ë°”ì´íŠ¸ë¡œ í…ŒìŠ¤íŠ¸"""
    image_data = base64.b64encode(image_bytes).decode("utf-8")
    return await run_full_pipeline(image_data, symptom_text)


async def run_full_pipeline(image_base64: str, symptom_text: str):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    results = {
        "input": {"symptom_text": symptom_text},
        "step1_image_analysis": None,
        "step1_5_kb_search": None,
        "step2_search": None,
        "step3_solution": None
    }

    # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„
    print("\n" + "=" * 60)
    print("[1ë‹¨ê³„] ì´ë¯¸ì§€ ë¶„ì„ + ì§ˆë¬¸ ì¦ê°• + Gate íŒë‹¨")
    print("=" * 60)

    analyzer = ImageAnalyzer(language="ko")
    image_analysis = await analyzer.analyze_images(
        images=[image_base64],
        symptom_text=symptom_text
    )

    results["step1_image_analysis"] = {
        "detected_problems": [p.value for p in image_analysis.detected_problems],
        "confidence_scores": image_analysis.confidence_scores,
        "description": image_analysis.description,
        "visual_evidence": image_analysis.visual_evidence,
        "augmented_query": image_analysis.augmented_query,
        "follow_up_questions": image_analysis.follow_up_questions,
        "specific_symptoms": image_analysis.specific_symptoms,
        "needs_search": image_analysis.needs_search.value,
        "search_skip_reason": image_analysis.search_skip_reason,
        "internal_solution": image_analysis.internal_solution
    }

    print(f"\n[ê°ì§€ëœ ë¬¸ì œ]: {[p.value for p in image_analysis.detected_problems]}")
    print(f"[í™•ì‹ ë„]: {image_analysis.confidence_scores}")
    print(f"\n[ì„¤ëª…]:\n{image_analysis.description}")
    print(f"\n[ì¦ê°•ëœ ê²€ìƒ‰ ì¿¼ë¦¬]:\n{image_analysis.augmented_query}")
    print(f"\n[ì¶”ê°€ ì§ˆë¬¸]:")
    for i, q in enumerate(image_analysis.follow_up_questions, 1):
        print(f"   {i}. {q}")
    print(f"\n[Gate íŒë‹¨]: {image_analysis.needs_search.value}")

    # 1.5ë‹¨ê³„: KB ê²€ìƒ‰ (ìœ ì‚¬ ì¦ìƒ ë§¤ì¹­)
    print("\n" + "=" * 60)
    print("[1.5ë‹¨ê³„] KB ê²€ìƒ‰ (ìœ ì‚¬ ì¦ìƒ ë§¤ì¹­)")
    print("=" * 60)

    kb_problem_name = None
    try:
        search_text = symptom_text + " " + image_analysis.description
        kb_results = search_kb(
            query=search_text,
            description=image_analysis.augmented_query,
            visual_signs=image_analysis.visual_evidence,
            top_k=3
        )

        results["step1_5_kb_search"] = {
            "total_found": kb_results.total_found,
            "search_method": kb_results.search_method,
            "matches": [
                {
                    "problem_name": r.entry.problem_name,
                    "problem_name_ko": r.entry.problem_name_ko,
                    "similarity_score": r.similarity_score,
                    "matched_symptoms": r.matched_symptoms,
                    "causes": r.entry.causes,
                    "quick_checks": r.entry.quick_checks
                }
                for r in kb_results.results
            ]
        }

        if kb_results.results:
            top_match = kb_results.results[0]
            kb_problem_name = top_match.entry.problem_name_ko
            print(f"\n[KB ë§¤ì¹­ ê²°ê³¼]: {kb_results.total_found}ê°œ ë°œê²¬ (ë°©ë²•: {kb_results.search_method})")
            for i, r in enumerate(kb_results.results, 1):
                print(f"   {i}. {r.entry.problem_name_ko} (score: {r.similarity_score:.2f})")
                print(f"      ì›ì¸: {r.entry.causes[:2]}")
        else:
            print("\n[KB ë§¤ì¹­ ê²°ê³¼]: ë§¤ì¹­ ì—†ìŒ")
    except Exception as e:
        print(f"\n[KB ê²€ìƒ‰ ì‹¤íŒ¨]: {e}")
        results["step1_5_kb_search"] = {"error": str(e)}

    # 2ë‹¨ê³„: Perplexity ê²€ìƒ‰
    print("\n" + "=" * 60)
    print("[2ë‹¨ê³„] Perplexity ê²€ìƒ‰ (ì–¸ì–´ë³„)")
    print("=" * 60)

    problem_type = image_analysis.detected_problems[0] if image_analysis.detected_problems else ProblemType.UNKNOWN

    if image_analysis.needs_search == SearchDecision.NOT_NEEDED:
        print("\n>> ê²€ìƒ‰ ìŠ¤í‚µ - ë‚´ë¶€ KBë¡œ í•´ê²°")
        search_result = PerplexitySearchResult(
            query=image_analysis.augmented_query,
            findings=[],
            citations=[],
            summary=image_analysis.internal_solution,
            tokens_used=0
        )
        results["step2_search"] = {"skipped": True, "reason": image_analysis.search_skip_reason}
    else:
        searcher = PerplexitySearcher(user_plan=UserPlan.FREE, language="ko")
        search_result = await searcher.search(
            augmented_query=image_analysis.augmented_query,
            problem_type=problem_type,
            kb_problem_name=kb_problem_name  # KB ë§¤ì¹­ ê²°ê³¼ ì „ë‹¬
        )

        results["step2_search"] = {
            "skipped": False,
            "query": search_result.query,
            "findings": [{"fact": e.fact, "source_url": e.source_url} for e in search_result.findings],
            "citations": search_result.citations,
            "summary": search_result.summary,
            "tokens_used": search_result.tokens_used
        }

        print(f"\n[ê²€ìƒ‰ ì¿¼ë¦¬]: {search_result.query[:100]}...")
        print(f"\n[Evidence] {len(search_result.findings)}ê°œ ë°œê²¬")
        for i, e in enumerate(search_result.findings[:3], 1):
            fact_preview = e.fact[:80] if e.fact else "(no fact)"
            print(f"   {i}. {fact_preview}...")
            print(f"      URL: {e.source_url}")

    # 3ë‹¨ê³„: êµ¬ì¡°í™” í¸ì§‘
    print("\n" + "=" * 60)
    print("[3ë‹¨ê³„] êµ¬ì¡°í™” í¸ì§‘")
    print("=" * 60)

    editor = StructuredEditor(language="ko")
    diagnosis = await editor.edit(
        image_analysis=image_analysis,
        search_result=search_result,
        symptom_text=symptom_text,
        problem_type=problem_type
    )

    results["step3_solution"] = {
        "observed": diagnosis.observed,
        "likely_causes": diagnosis.likely_causes,
        "immediate_checks": diagnosis.immediate_checks,
        "solutions": diagnosis.solutions,
        "need_more_info": diagnosis.need_more_info
    }

    print(f"\n[ê´€ì°°ëœ ì¦ìƒ]: {diagnosis.observed}")
    print(f"\n[ì›ì¸]: {len(diagnosis.likely_causes)}ê°œ")
    print(f"[í•´ê²°ì±…]: {len(diagnosis.solutions)}ê°œ")

    return results


def save_markdown(results: dict, output_path: str = "troubleshoot_result.md"):
    """ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥"""
    step1 = results['step1_image_analysis']
    step2 = results['step2_search']
    step3 = results['step3_solution']

    md = f"""# ğŸ” 3D í”„ë¦°í„° ë¬¸ì œ ì§„ë‹¨ ê²°ê³¼

## ì…ë ¥
- **ì¦ìƒ**: "{results['input']['symptom_text']}"

---

## ğŸ“¸ 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ + ì§ˆë¬¸ ì¦ê°•

### ê°ì§€ëœ ë¬¸ì œ
"""
    for p in step1['detected_problems']:
        conf = step1['confidence_scores'].get(p, 'N/A')
        md += f"- **{p}** (í™•ì‹ ë„: {conf})\n"

    md += f"""
### ì„¤ëª…
{step1['description']}

### ì‹œê°ì  ì¦ê±°
"""
    for ev in step1['visual_evidence']:
        md += f"- {ev}\n"

    md += f"""
### ğŸ” ì¦ê°•ëœ ê²€ìƒ‰ ì¿¼ë¦¬ (Augmented Query)
```
{step1['augmented_query']}
```

### â“ ì¶”ê°€ ì§ˆë¬¸ (Follow-up Questions)
"""
    for i, q in enumerate(step1['follow_up_questions'], 1):
        md += f"{i}. {q}\n"

    md += f"""
### ğŸš¦ Gate íŒë‹¨
- **ê²€ìƒ‰ í•„ìš”**: `{step1['needs_search']}`
"""
    if step1['search_skip_reason']:
        md += f"- **ìŠ¤í‚µ ì´ìœ **: {step1['search_skip_reason']}\n"
    if step1['internal_solution']:
        md += f"\n**ë‚´ë¶€ ì†”ë£¨ì…˜**:\n{step1['internal_solution']}\n"

    md += """
---

## ğŸ” 2ë‹¨ê³„: Perplexity ê²€ìƒ‰

"""
    if step2.get('skipped'):
        md += f"### â­ï¸ ê²€ìƒ‰ ìŠ¤í‚µ\n- ì´ìœ : {step2.get('reason', 'N/A')}\n"
    else:
        md += f"""### ê²€ìƒ‰ ì¿¼ë¦¬
```
{step2['query']}
```

### Evidence ({len(step2['findings'])}ê°œ)

| # | ì‚¬ì‹¤ | ì¶œì²˜ |
|---|------|------|
"""
        for i, f in enumerate(step2['findings'], 1):
            fact = f['fact'][:80].replace('\n', ' ') + '...' if len(f['fact']) > 80 else f['fact']
            md += f"| {i} | {fact} | {f['source_url']} |\n"

        md += f"""
### ğŸ“ Citations
"""
        for url in step2.get('citations', []):
            md += f"- {url}\n"

        md += f"""
### Raw Summary
```
{step2['summary'][:1500]}
```
"""

    md += """
---

## ğŸ“‹ 3ë‹¨ê³„: êµ¬ì¡°í™”ëœ ê²°ê³¼

"""
    md += f"""### ê´€ì°°ëœ ì¦ìƒ
{step3['observed']}

### ğŸ¯ ê°€ëŠ¥í•œ ì›ì¸
"""
    for c in step3['likely_causes']:
        md += f"- **{c.get('cause', 'N/A')}** (ì¶œì²˜: {c.get('source', 'N/A')})\n"

    md += """
### âœ… ì¦‰ì‹œ í™•ì¸
"""
    for ch in step3['immediate_checks']:
        md += f"- {ch}\n"

    md += """
### ğŸ”§ í•´ê²°ì±…
"""
    for i, s in enumerate(step3['solutions'], 1):
        md += f"\n**{i}. {s.get('title', 'N/A')}** (ë‚œì´ë„: {s.get('difficulty', 'N/A')})\n"
        md += f"- ì¶œì²˜: {s.get('source', 'N/A')}\n"
        for step in s.get('steps', []):
            md += f"  - {step}\n"

    md += """
### â“ ì¶”ê°€ ì •ë³´ í•„ìš”
"""
    for info in step3['need_more_info']:
        md += f"- {info}\n"

    md += f"""
---

## ğŸ“Š Raw JSON

<details>
<summary>ì „ì²´ ë°ì´í„°</summary>

```json
{json.dumps(results, indent=2, ensure_ascii=False)}
```

</details>
"""

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md)
    print(f"\n[OK] ì €ì¥ë¨: {output_path}")


async def main():
    """ì´ë¯¸ì§€ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python test_inline.py <ì´ë¯¸ì§€_ê²½ë¡œ>")
        return

    image_path = sys.argv[1]
    with open(image_path, 'rb') as f:
        image_bytes = f.read()

    results = await test_with_image_bytes(image_bytes)
    save_markdown(results)


if __name__ == "__main__":
    asyncio.run(main())
