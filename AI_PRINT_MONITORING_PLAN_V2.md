# 3D í”„ë¦°í„° ì¶œë ¥ ë¶ˆëŸ‰ ê°ì§€ AI ì‹œìŠ¤í…œ ê°œë°œ ê³„íš v2.0
## Spaghetti Detective ëª¨ë¸ ê¸°ë°˜ + ì‹¤íŒ¨ ì¥ë©´ ìë™ ìˆ˜ì§‘

## ğŸ“‹ ëª©ì°¨
1. [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [ê¸°ìˆ  ìŠ¤íƒ (ì—…ë°ì´íŠ¸)](#ê¸°ìˆ -ìŠ¤íƒ)
4. [ê°œë°œ ë‹¨ê³„ë³„ ê³„íš](#ê°œë°œ-ë‹¨ê³„ë³„-ê³„íš)
5. [ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ ì‹œìŠ¤í…œ](#ì‹¤íŒ¨-ì¥ë©´-ìˆ˜ì§‘-ì‹œìŠ¤í…œ)
6. [API ì„¤ê³„](#api-ì„¤ê³„)
7. [í”„ë¡ íŠ¸ì—”ë“œ í†µí•©](#í”„ë¡ íŠ¸ì—”ë“œ-í†µí•©)
8. [ë°°í¬ ë° ìš´ì˜](#ë°°í¬-ë°-ìš´ì˜)

---

## í”„ë¡œì íŠ¸ ê°œìš”

### ëª©í‘œ
WebRTC ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°ì„ í™œìš©í•˜ì—¬ 3D í”„ë¦°í„° ì¶œë ¥ ê³¼ì •ì„ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§í•˜ê³ , **ì‚¬ì „ í•™ìŠµëœ Spaghetti Detective AI ëª¨ë¸**ë¡œ ë¶ˆëŸ‰ì„ ê°ì§€:
- **ìŠ¤íŒŒê²Œí‹°í™” (Spaghetti)**: í•„ë¼ë©˜íŠ¸ê°€ ì—‰ì¼œì„œ ì¶œë ¥ë˜ëŠ” í˜„ìƒ
- **ë ˆì´ì–´ ë¶„ë¦¬ (Layer Separation)**: ë ˆì´ì–´ ê°„ ì ‘ì°© ë¶ˆëŸ‰
- **ì™€í•‘ (Warping)**: ì¶œë ¥ë¬¼ ëª¨ì„œë¦¬ê°€ ë“¤ëœ¨ëŠ” í˜„ìƒ
- **ë…¸ì¦ ë§‰í˜ (Clogging)**: í•„ë¼ë©˜íŠ¸ ì••ì¶œ ë¶ˆëŸ‰
- **ì„œí¬íŠ¸ ë¶•ê´´ (Support Failure)**: ì„œí¬íŠ¸ êµ¬ì¡° ë¶•ê´´
- **ì²« ë ˆì´ì–´ ì‹¤íŒ¨ (First Layer Failure)**: ë² ë“œ ì ‘ì°© ì‹¤íŒ¨

### í•µì‹¬ ê¸°ëŠ¥
1. **ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§**: WebRTC ìŠ¤íŠ¸ë¦¼ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ë° ë¶„ì„
2. **AI ë¶ˆëŸ‰ ê°ì§€**: **Spaghetti Detective ì‚¬ì „í•™ìŠµ ëª¨ë¸** ì‚¬ìš© (í•™ìŠµ ë¶ˆí•„ìš”!)
3. **ì˜ˆì¸¡ ì •ë³´ ìƒì„±**: ë¶ˆëŸ‰ íƒ€ì…, ì‹ ë¢°ë„, ìœ„ì¹˜, ì‹œê°„ ë“±
4. **MQTT ì•Œë¦¼**: ë¶ˆëŸ‰ ê°ì§€ ì‹œ ì‹¤ì‹œê°„ ì•Œë¦¼
5. **ì‹¤íŒ¨ ì¥ë©´ ìë™ ìˆ˜ì§‘**: ê°ì§€ëœ ë¶ˆëŸ‰ í”„ë ˆì„ì„ DB/Storageì— ìë™ ì €ì¥ â­ **NEW**
6. **ë°ì´í„°ì…‹ êµ¬ì¶•**: ìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ í–¥í›„ ì»¤ìŠ¤í…€ ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥ â­ **NEW**
7. **ì´ë ¥ ê´€ë¦¬**: DBì— ê°ì§€ ì´ë ¥ ì €ì¥ ë° ëŒ€ì‹œë³´ë“œ ì œê³µ

### âš¡ ì£¼ìš” ë³€ê²½ì‚¬í•­ (v2.0)
- âœ… **í•™ìŠµ ë¶ˆí•„ìš”**: Spaghetti Detective ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
- âœ… **ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥**: ê°œë°œ ê¸°ê°„ 12ì£¼ â†’ **4ì£¼ë¡œ ë‹¨ì¶•**
- âœ… **ì‹¤íŒ¨ ì¥ë©´ ìë™ ì €ì¥**: ê°ì§€ ì‹œ í”„ë ˆì„ + ë©”íƒ€ë°ì´í„° ìë™ DB ì €ì¥
- âœ… **ë°ì´í„°ì…‹ ì¶•ì **: ì‹¤ì „ ë°ì´í„° ìë™ ìˆ˜ì§‘ìœ¼ë¡œ í–¥í›„ ê°œì„  ê°€ëŠ¥
- âœ… **ë¹„ìš© ì ˆê°**: ë¼ë²¨ë§ ì‘ì—… ë¶ˆí•„ìš”

---

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Frontend (Web)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ CameraFeed   â”‚  â”‚ AI Dashboard â”‚  â”‚ Alert Panel  â”‚      â”‚
â”‚  â”‚ (WebRTC)     â”‚  â”‚ (Detection)  â”‚  â”‚ (MQTT Sub)   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚         â”‚                  â”‚                  â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â”‚                  â”‚                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚                  â”‚ HTTP API         â”‚ MQTT          â”‚
â”‚         â–¼                  â–¼                  â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚           FastAPI Server (main.py)               â”‚        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚        â”‚
â”‚  â”‚  â”‚ WebRTC     â”‚  â”‚ AI Model   â”‚  â”‚ MQTT       â”‚ â”‚        â”‚
â”‚  â”‚  â”‚ Frame      â”‚  â”‚ Inference  â”‚  â”‚ Publisher  â”‚ â”‚        â”‚
â”‚  â”‚  â”‚ Capture    â”‚  â”‚ Service    â”‚  â”‚            â”‚ â”‚        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚           â”‚               â”‚                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  Spaghetti Detective Model (Pre-trained) â­             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                   â”‚
â”‚  â”‚  â”‚ - No Training Required           â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚ - 3D Print Failure Specialized   â”‚  â”‚                   â”‚
â”‚  â”‚  â”‚ - High Accuracy (proven)         â”‚  â”‚                   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚           â”‚                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Failure Scene Collector â­ NEW      â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚                    â”‚
â”‚  â”‚  â”‚ Auto-save detected frames    â”‚   â”‚                    â”‚
â”‚  â”‚  â”‚ Build training dataset       â”‚   â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚           â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Supabase DB      â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚ detections   â”‚  â”‚  - ê°ì§€ ì´ë ¥
   â”‚  â”‚ failure_scenesâ”‚ â”‚  - ì‹¤íŒ¨ ì¥ë©´ (NEW) â­
   â”‚  â”‚ print_jobs   â”‚  â”‚  - ì¶œë ¥ ì‘ì—…
   â”‚  â”‚ cameras      â”‚  â”‚  - ì¹´ë©”ë¼ ì •ë³´
   â”‚  â”‚ alerts       â”‚  â”‚  - ì•Œë¦¼ ì´ë ¥
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Supabase Storage   â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
   â”‚  â”‚ failure_framesâ”‚ â”‚  - ë¶ˆëŸ‰ í”„ë ˆì„ ì´ë¯¸ì§€ â­
   â”‚  â”‚ annotated_imgsâ”‚ â”‚  - ë°”ìš´ë”©ë°•ìŠ¤ í‘œì‹œ ì´ë¯¸ì§€
   â”‚  â”‚ video_clips  â”‚  â”‚  - ë¶ˆëŸ‰ ë°œìƒ ì „í›„ ì˜ìƒ (ì„ íƒ)
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ê¸°ìˆ  ìŠ¤íƒ (ì—…ë°ì´íŠ¸)

### Backend (Python)
- **FastAPI**: REST API ì„œë²„
- **OpenCV**: ë¹„ë””ì˜¤ í”„ë ˆì„ ì²˜ë¦¬
- **PyTorch**: ë”¥ëŸ¬ë‹ ì¶”ë¡ 
- **Spaghetti Detective Model**: ì‚¬ì „í•™ìŠµ 3D í”„ë¦°í„° ë¶ˆëŸ‰ ê°ì§€ ëª¨ë¸ â­ **í•µì‹¬**
- **paho-mqtt**: MQTT í´ë¼ì´ì–¸íŠ¸
- **Pillow**: ì´ë¯¸ì§€ ì²˜ë¦¬

### AI Model (ì‚¬ì „í•™ìŠµ - í•™ìŠµ ë¶ˆí•„ìš”!)
- **Spaghetti Detective Pre-trained Model**
  - ì¶œì²˜: [TheSpaghettiDetective/ml_api](https://github.com/TheSpaghettiDetective/ml_api)
  - í¬ê¸°: ~50MB
  - ì¶”ë¡  ì†ë„: ~30 FPS (GPU)
  - íŠ¹ì§•: 3D í”„ë¦°í„° ì „ìš©, ì‹¤ì „ ê²€ì¦ë¨
  - **ë¼ë²¨ë§/í•™ìŠµ ë¶ˆí•„ìš”!** âœ…

### Frontend (React/TypeScript)
- **WebRTC API**: ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°
- **MQTT.js**: ì‹¤ì‹œê°„ ì•Œë¦¼ ìˆ˜ì‹ 
- **Canvas API**: ê°ì§€ ê²°ê³¼ ì˜¤ë²„ë ˆì´
- **React Query**: ì´ë ¥ ë°ì´í„° ê´€ë¦¬

### Database & Storage
- **Supabase PostgreSQL**: ë©”íƒ€ë°ì´í„° ì €ì¥
- **Supabase Storage**: ì‹¤íŒ¨ ì¥ë©´ ì´ë¯¸ì§€/ì˜ìƒ ì €ì¥ â­
- **Redis** (ì„ íƒ): ì‹¤ì‹œê°„ ìƒíƒœ ìºì‹±

---

## ê°œë°œ ë‹¨ê³„ë³„ ê³„íš (4ì£¼ë¡œ ë‹¨ì¶•!)

### Phase 1: Spaghetti Detective ëª¨ë¸ í†µí•© (Week 1)

#### 1.1 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜

**íŒŒì¼**: `setup_model.py`

```python
"""
Spaghetti Detective ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •
"""
import os
import requests
from pathlib import Path
import torch

MODEL_DIR = Path("./models")
MODEL_DIR.mkdir(exist_ok=True)

def download_spaghetti_detective_model():
    """
    Spaghetti Detective ì‚¬ì „í•™ìŠµ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

    ì¶œì²˜: https://github.com/TheSpaghettiDetective/ml_api
    """
    model_url = "https://github.com/TheSpaghettiDetective/ml_api/releases/download/v1.0/spaghetti_detector.pth"
    model_path = MODEL_DIR / "spaghetti_detector.pth"

    if model_path.exists():
        print(f"âœ… Model already exists: {model_path}")
        return model_path

    print(f"ğŸ“¥ Downloading Spaghetti Detective model...")
    response = requests.get(model_url, stream=True)
    response.raise_for_status()

    with open(model_path, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

    print(f"âœ… Model downloaded: {model_path}")
    return model_path

def verify_model():
    """ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    model_path = MODEL_DIR / "spaghetti_detector.pth"

    try:
        # PyTorch ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
        model = torch.load(model_path, map_location='cpu')
        print("âœ… Model verification successful")
        return True
    except Exception as e:
        print(f"âŒ Model verification failed: {e}")
        return False

if __name__ == "__main__":
    # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
    model_path = download_spaghetti_detective_model()

    # ê²€ì¦
    if verify_model():
        print("\nğŸ‰ Setup complete! Ready to use.")
    else:
        print("\nâŒ Setup failed. Please check the model file.")
```

**ì‹¤í–‰**:
```bash
python setup_model.py
```

**ì‘ì—…**:
- [ ] Spaghetti Detective ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] ëª¨ë¸ ë¡œë“œ í…ŒìŠ¤íŠ¸
- [ ] ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬

#### 1.2 AI ì¶”ë¡  ì„œë¹„ìŠ¤ (ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš©)

**íŒŒì¼**: `ai_inference_pretrained.py`

```python
"""
Spaghetti Detective ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê¸°ë°˜ ì¶”ë¡  ì„œë¹„ìŠ¤
"""
import cv2
import numpy as np
import torch
from typing import List, Dict, Optional
import logging
from datetime import datetime
from pathlib import Path

logger = logging.getLogger("uvicorn.error")

MODEL_PATH = "./models/spaghetti_detector.pth"
CONFIDENCE_THRESHOLD = 0.7  # Spaghetti Detective ê¶Œì¥ê°’

class SpaghettiDetectiveInference:
    """Spaghetti Detective ì¶”ë¡  ì„œë¹„ìŠ¤"""

    def __init__(self, model_path: str = MODEL_PATH):
        """
        Args:
            model_path: ì‚¬ì „í•™ìŠµ ëª¨ë¸ ê²½ë¡œ
        """
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = self._load_model(model_path)
        self.model.eval()
        logger.info(f"[AI] Spaghetti Detective model loaded on {self.device}")

    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        if not Path(model_path).exists():
            raise FileNotFoundError(f"Model not found: {model_path}")

        model = torch.load(model_path, map_location=self.device)
        model.to(self.device)
        return model

    def preprocess_frame(self, frame: np.ndarray) -> torch.Tensor:
        """
        í”„ë ˆì„ ì „ì²˜ë¦¬

        Spaghetti Detective ì…ë ¥ í˜•ì‹:
        - í¬ê¸°: 300x300
        - ì •ê·œí™”: ImageNet í‰ê· /í‘œì¤€í¸ì°¨
        """
        # ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(frame, (300, 300))

        # BGR â†’ RGB
        rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)

        # ì •ê·œí™”
        normalized = rgb.astype(np.float32) / 255.0
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        normalized = (normalized - mean) / std

        # Tensor ë³€í™˜ [H, W, C] â†’ [C, H, W]
        tensor = torch.from_numpy(normalized).permute(2, 0, 1)
        tensor = tensor.unsqueeze(0)  # Batch dimension

        return tensor.to(self.device)

    async def predict(
        self,
        frame: np.ndarray,
        conf_threshold: float = CONFIDENCE_THRESHOLD
    ) -> List[Dict]:
        """
        ë¶ˆëŸ‰ ê°ì§€ ì¶”ë¡ 

        Args:
            frame: OpenCV ì´ë¯¸ì§€ (BGR)
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’

        Returns:
            ê°ì§€ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            [
                {
                    'detection_type': 'spaghetti',
                    'confidence': 0.95,
                    'severity': 'critical',
                    'timestamp': '2025-01-26T10:30:00Z',
                    'bbox': [x, y, w, h]  # ëª¨ë¸ì´ ì œê³µí•˜ëŠ” ê²½ìš°
                },
                ...
            ]
        """
        if frame is None or frame.size == 0:
            logger.warning("[AI] Empty frame received")
            return []

        try:
            # ì „ì²˜ë¦¬
            input_tensor = self.preprocess_frame(frame)

            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(input_tensor)

            # ê²°ê³¼ íŒŒì‹±
            detections = self._parse_outputs(outputs, conf_threshold)

            if detections:
                logger.info(f"[AI] Detected {len(detections)} failure(s)")
                for det in detections:
                    logger.info(
                        f"[AI]   - {det['detection_type']}: "
                        f"{det['confidence']:.2f} ({det['severity']})"
                    )

            return detections

        except Exception as e:
            logger.error(f"[AI] Prediction failed: {str(e)}")
            return []

    def _parse_outputs(
        self,
        outputs: torch.Tensor,
        conf_threshold: float
    ) -> List[Dict]:
        """
        ëª¨ë¸ ì¶œë ¥ íŒŒì‹±

        Spaghetti Detective ì¶œë ¥ í˜•ì‹:
        - outputs['failure_detected']: bool
        - outputs['confidence']: float (0-1)
        - outputs['failure_type']: str ('spaghetti', 'warping', etc.)
        - outputs['bbox']: [x, y, w, h] (ì„ íƒì )
        """
        detections = []

        # ë¶ˆëŸ‰ ê°ì§€ ì—¬ë¶€
        if not outputs.get('failure_detected', False):
            return []

        confidence = outputs.get('confidence', 0.0)

        if confidence < conf_threshold:
            return []

        failure_type = outputs.get('failure_type', 'unknown')

        # ì‹¬ê°ë„ ë§¤í•‘
        severity_map = {
            'spaghetti': 'critical',
            'warping': 'high',
            'layer_separation': 'high',
            'clogging': 'medium',
            'support_failure': 'medium',
            'first_layer_fail': 'critical'
        }

        detection = {
            'detection_type': failure_type,
            'confidence': round(confidence, 4),
            'severity': severity_map.get(failure_type, 'medium'),
            'timestamp': datetime.utcnow().isoformat() + 'Z'
        }

        # ë°”ìš´ë”© ë°•ìŠ¤ (ìˆëŠ” ê²½ìš°)
        if 'bbox' in outputs:
            detection['bbox'] = outputs['bbox']

        detections.append(detection)

        return detections

    def draw_detections(
        self,
        frame: np.ndarray,
        detections: List[Dict]
    ) -> np.ndarray:
        """
        í”„ë ˆì„ì— ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        """
        annotated = frame.copy()

        color_map = {
            'critical': (0, 0, 255),    # ë¹¨ê°•
            'high': (0, 165, 255),      # ì£¼í™©
            'medium': (0, 255, 255),    # ë…¸ë‘
            'low': (0, 255, 0)          # ì´ˆë¡
        }

        for det in detections:
            severity = det['severity']
            conf = det['confidence']
            det_type = det['detection_type']

            color = color_map.get(severity, (255, 255, 255))

            # ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆìœ¼ë©´ ê·¸ë¦¬ê¸°
            if 'bbox' in det:
                x, y, w, h = det['bbox']
                cv2.rectangle(annotated, (x, y), (x+w, y+h), color, 3)

            # í…ìŠ¤íŠ¸ ë¼ë²¨
            label = f"{det_type}: {conf:.2f}"

            # í™”ë©´ ìƒë‹¨ì— ê²½ê³  í‘œì‹œ
            cv2.putText(
                annotated,
                f"WARNING: {label.upper()}",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                1.0,
                color,
                2
            )

            # Severity í‘œì‹œ
            cv2.putText(
                annotated,
                f"Severity: {severity.upper()}",
                (10, 70),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                color,
                2
            )

        return annotated

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_ai_service: Optional[SpaghettiDetectiveInference] = None

def get_ai_service() -> SpaghettiDetectiveInference:
    """AI ì„œë¹„ìŠ¤ ì‹±ê¸€í†¤"""
    global _ai_service
    if _ai_service is None:
        _ai_service = SpaghettiDetectiveInference()
    return _ai_service
```

**ì‘ì—…**:
- [ ] Spaghetti Detective ëª¨ë¸ í†µí•©
- [ ] ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
- [ ] ì¶”ë¡  í…ŒìŠ¤íŠ¸

---

### Phase 2: ì‹¤íŒ¨ ì¥ë©´ ìë™ ìˆ˜ì§‘ ì‹œìŠ¤í…œ (Week 1) â­ **í•µì‹¬**

#### 2.1 ì‹¤íŒ¨ ì¥ë©´ DB ìŠ¤í‚¤ë§ˆ

**Supabase SQL**:

```sql
-- ì‹¤íŒ¨ ì¥ë©´ í…Œì´ë¸” (NEW)
CREATE TABLE failure_scenes (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES auth.users(id),
    device_uuid UUID NOT NULL,
    detection_id UUID REFERENCES print_detections(id),
    print_job_id UUID REFERENCES print_jobs(id),

    -- ê°ì§€ ì •ë³´
    failure_type VARCHAR(50) NOT NULL,
    confidence FLOAT NOT NULL,
    severity VARCHAR(20) NOT NULL,

    -- í”„ë ˆì„ ì •ë³´
    frame_timestamp TIMESTAMPTZ NOT NULL,
    frame_number INTEGER,

    -- ì´ë¯¸ì§€ ì €ì¥ (Supabase Storage)
    original_frame_url TEXT NOT NULL,      -- ì›ë³¸ í”„ë ˆì„
    annotated_frame_url TEXT,              -- ë°”ìš´ë”©ë°•ìŠ¤ í‘œì‹œ
    before_frames_url TEXT,                -- ë¶ˆëŸ‰ ë°œìƒ ì „ í”„ë ˆì„ (ì„ íƒ)
    after_frames_url TEXT,                 -- ë¶ˆëŸ‰ ë°œìƒ í›„ í”„ë ˆì„ (ì„ íƒ)

    -- ì¶œë ¥ ì»¨í…ìŠ¤íŠ¸
    layer_number INTEGER,
    print_progress FLOAT,
    nozzle_temp FLOAT,
    bed_temp FLOAT,
    print_speed FLOAT,

    -- ë¼ë²¨ë§ ìƒíƒœ (í–¥í›„ í•™ìŠµìš©)
    is_verified BOOLEAN DEFAULT FALSE,     -- ì‚¬ëŒì´ ê²€ì¦í–ˆëŠ”ì§€
    verified_by UUID REFERENCES auth.users(id),
    verified_at TIMESTAMPTZ,
    is_false_positive BOOLEAN DEFAULT FALSE,
    corrected_type VARCHAR(50),            -- ìˆ˜ì •ëœ íƒ€ì… (ìˆëŠ” ê²½ìš°)

    -- ë°ì´í„°ì…‹ í¬í•¨ ì—¬ë¶€
    include_in_dataset BOOLEAN DEFAULT TRUE,
    dataset_split VARCHAR(20),             -- 'train', 'val', 'test'

    -- ë©”íƒ€ë°ì´í„°
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_failure_scenes_user ON failure_scenes(user_id, created_at DESC);
CREATE INDEX idx_failure_scenes_device ON failure_scenes(device_uuid, created_at DESC);
CREATE INDEX idx_failure_scenes_type ON failure_scenes(failure_type);
CREATE INDEX idx_failure_scenes_verified ON failure_scenes(is_verified, include_in_dataset);

-- RLS ì •ì±…
ALTER TABLE failure_scenes ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Users can view own failure scenes"
    ON failure_scenes FOR SELECT
    USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own failure scenes"
    ON failure_scenes FOR INSERT
    WITH CHECK (auth.uid() = user_id);
```

#### 2.2 ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ ì„œë¹„ìŠ¤

**íŒŒì¼**: `failure_scene_collector.py`

```python
"""
ì‹¤íŒ¨ ì¥ë©´ ìë™ ìˆ˜ì§‘ ì„œë¹„ìŠ¤
- ê°ì§€ëœ ë¶ˆëŸ‰ í”„ë ˆì„ ìë™ ì €ì¥
- ì „í›„ ì»¨í…ìŠ¤íŠ¸ í”„ë ˆì„ ì €ì¥ (ì„ íƒ)
- ë©”íƒ€ë°ì´í„° DB ì €ì¥
"""
import cv2
import numpy as np
from typing import Dict, List, Optional
import logging
from datetime import datetime
from pathlib import Path
import uuid
from collections import deque

from supabase_storage import (
    upload_failure_frame,
    upload_failure_video_clip
)
from supabase_db import save_failure_scene

logger = logging.getLogger("uvicorn.error")

class FailureSceneCollector:
    """ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ê¸°"""

    def __init__(
        self,
        device_uuid: str,
        user_id: str,
        print_job_id: Optional[str] = None,
        buffer_size: int = 30,  # 30í”„ë ˆì„ ë²„í¼ (ì•½ 5ì´ˆ)
        save_context: bool = True  # ì „í›„ í”„ë ˆì„ ì €ì¥ ì—¬ë¶€
    ):
        """
        Args:
            device_uuid: ë””ë°”ì´ìŠ¤ UUID
            user_id: ì‚¬ìš©ì ID
            print_job_id: ì¶œë ¥ ì‘ì—… ID
            buffer_size: ì „í›„ í”„ë ˆì„ ë²„í¼ í¬ê¸°
            save_context: ì „í›„ ì»¨í…ìŠ¤íŠ¸ í”„ë ˆì„ ì €ì¥ ì—¬ë¶€
        """
        self.device_uuid = device_uuid
        self.user_id = user_id
        self.print_job_id = print_job_id
        self.save_context = save_context

        # í”„ë ˆì„ ë²„í¼ (ìµœê·¼ Nê°œ í”„ë ˆì„ ì €ì¥)
        self.frame_buffer: deque = deque(maxlen=buffer_size)
        self.frame_counter = 0

    def add_frame(self, frame: np.ndarray):
        """
        í”„ë ˆì„ì„ ë²„í¼ì— ì¶”ê°€

        Args:
            frame: OpenCV ì´ë¯¸ì§€
        """
        if self.save_context:
            self.frame_buffer.append({
                'frame': frame.copy(),
                'timestamp': datetime.utcnow(),
                'frame_number': self.frame_counter
            })

        self.frame_counter += 1

    async def collect_failure_scene(
        self,
        current_frame: np.ndarray,
        annotated_frame: np.ndarray,
        detection: Dict,
        print_context: Optional[Dict] = None
    ) -> str:
        """
        ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ ë° ì €ì¥

        Args:
            current_frame: í˜„ì¬ ì›ë³¸ í”„ë ˆì„
            annotated_frame: ì–´ë…¸í…Œì´ì…˜ëœ í”„ë ˆì„
            detection: ê°ì§€ ì •ë³´
            print_context: ì¶œë ¥ ì»¨í…ìŠ¤íŠ¸ (ì˜¨ë„, ì†ë„ ë“±)

        Returns:
            failure_scene_id: ì €ì¥ëœ ì¥ë©´ ID
        """
        scene_id = str(uuid.uuid4())

        logger.info(f"[Collector] Collecting failure scene: {scene_id}")

        try:
            # 1. í˜„ì¬ í”„ë ˆì„ ì €ì¥
            original_url = await upload_failure_frame(
                user_id=self.user_id,
                device_uuid=self.device_uuid,
                scene_id=scene_id,
                frame=current_frame,
                frame_type='original'
            )

            annotated_url = await upload_failure_frame(
                user_id=self.user_id,
                device_uuid=self.device_uuid,
                scene_id=scene_id,
                frame=annotated_frame,
                frame_type='annotated'
            )

            logger.info(f"[Collector] Frames uploaded: {scene_id}")

            # 2. ì „í›„ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ (ì„ íƒ)
            before_url = None
            after_url = None

            if self.save_context and len(self.frame_buffer) > 0:
                # ë¶ˆëŸ‰ ë°œìƒ ì „ í”„ë ˆì„ (ìµœê·¼ 15í”„ë ˆì„)
                before_frames = list(self.frame_buffer)[-15:]
                before_url = await self._save_context_video(
                    scene_id,
                    before_frames,
                    'before'
                )

                logger.info(f"[Collector] Context frames saved: {scene_id}")

            # 3. DBì— ë©”íƒ€ë°ì´í„° ì €ì¥
            scene_data = {
                'id': scene_id,
                'user_id': self.user_id,
                'device_uuid': self.device_uuid,
                'print_job_id': self.print_job_id,
                'detection_id': detection.get('detection_id'),

                'failure_type': detection['detection_type'],
                'confidence': detection['confidence'],
                'severity': detection['severity'],

                'frame_timestamp': detection['timestamp'],
                'frame_number': self.frame_counter,

                'original_frame_url': original_url,
                'annotated_frame_url': annotated_url,
                'before_frames_url': before_url,
                'after_frames_url': after_url,

                # ì¶œë ¥ ì»¨í…ìŠ¤íŠ¸
                'layer_number': print_context.get('layer_number') if print_context else None,
                'print_progress': print_context.get('progress') if print_context else None,
                'nozzle_temp': print_context.get('nozzle_temp') if print_context else None,
                'bed_temp': print_context.get('bed_temp') if print_context else None,
                'print_speed': print_context.get('print_speed') if print_context else None,
            }

            await save_failure_scene(scene_data)

            logger.info(
                f"[Collector] âœ… Failure scene saved: {scene_id} "
                f"({detection['detection_type']})"
            )

            return scene_id

        except Exception as e:
            logger.error(f"[Collector] Failed to collect scene: {str(e)}")
            raise

    async def _save_context_video(
        self,
        scene_id: str,
        frames: List[Dict],
        video_type: str  # 'before' or 'after'
    ) -> Optional[str]:
        """
        ì „í›„ í”„ë ˆì„ì„ ë¹„ë””ì˜¤ë¡œ ì €ì¥

        Args:
            scene_id: ì¥ë©´ ID
            frames: í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
            video_type: 'before' or 'after'

        Returns:
            ë¹„ë””ì˜¤ URL
        """
        if not frames:
            return None

        try:
            # ì„ì‹œ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„±
            temp_video_path = f"/tmp/{scene_id}_{video_type}.mp4"

            # VideoWriter ì„¤ì •
            first_frame = frames[0]['frame']
            height, width = first_frame.shape[:2]

            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            fps = 6  # 6 FPSë¡œ ì €ì¥ (ë¹ ë¥´ê²Œ ì¬ìƒ)
            writer = cv2.VideoWriter(
                temp_video_path,
                fourcc,
                fps,
                (width, height)
            )

            # í”„ë ˆì„ ì“°ê¸°
            for frame_data in frames:
                writer.write(frame_data['frame'])

            writer.release()

            # Supabase Storage ì—…ë¡œë“œ
            video_url = await upload_failure_video_clip(
                user_id=self.user_id,
                device_uuid=self.device_uuid,
                scene_id=scene_id,
                video_path=temp_video_path,
                video_type=video_type
            )

            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            Path(temp_video_path).unlink(missing_ok=True)

            logger.info(f"[Collector] Context video saved: {video_type}")

            return video_url

        except Exception as e:
            logger.error(f"[Collector] Failed to save context video: {str(e)}")
            return None
```

**ì‘ì—…**:
- [ ] ì‹¤íŒ¨ ì¥ë©´ DB ìŠ¤í‚¤ë§ˆ ìƒì„±
- [ ] ìˆ˜ì§‘ ì„œë¹„ìŠ¤ êµ¬í˜„
- [ ] Storage ì—…ë¡œë“œ í•¨ìˆ˜ êµ¬í˜„
- [ ] í…ŒìŠ¤íŠ¸

---

### Phase 3: í†µí•© ë° API êµ¬í˜„ (Week 2)

#### 3.1 Supabase Storage ì—…ë¡œë“œ í•¨ìˆ˜

**íŒŒì¼**: `supabase_storage.py` (ì¶”ê°€)

```python
"""
Supabase Storage ì—…ë¡œë“œ í•¨ìˆ˜
"""
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, Optional
import logging

from supabase_client import get_supabase_client

logger = logging.getLogger("uvicorn.error")

BUCKET_FAILURE_FRAMES = "failure_frames"
BUCKET_FAILURE_VIDEOS = "failure_videos"

async def upload_failure_frame(
    user_id: str,
    device_uuid: str,
    scene_id: str,
    frame: np.ndarray,
    frame_type: str = 'original'  # 'original' or 'annotated'
) -> str:
    """
    ì‹¤íŒ¨ í”„ë ˆì„ì„ Supabase Storageì— ì—…ë¡œë“œ

    Args:
        user_id: ì‚¬ìš©ì ID
        device_uuid: ë””ë°”ì´ìŠ¤ UUID
        scene_id: ì¥ë©´ ID
        frame: OpenCV ì´ë¯¸ì§€
        frame_type: 'original' or 'annotated'

    Returns:
        Public URL
    """
    try:
        supabase = get_supabase_client()

        # íŒŒì¼ëª… ìƒì„±
        filename = f"{user_id}/{device_uuid}/{scene_id}_{frame_type}.jpg"

        # ì´ë¯¸ì§€ ì¸ì½”ë”©
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
        image_bytes = buffer.tobytes()

        # ì—…ë¡œë“œ
        response = supabase.storage.from_(BUCKET_FAILURE_FRAMES).upload(
            path=filename,
            file=image_bytes,
            file_options={"content-type": "image/jpeg"}
        )

        # Public URL ìƒì„±
        public_url = supabase.storage.from_(BUCKET_FAILURE_FRAMES).get_public_url(filename)

        logger.info(f"[Storage] Frame uploaded: {filename}")

        return public_url

    except Exception as e:
        logger.error(f"[Storage] Upload failed: {str(e)}")
        raise

async def upload_failure_video_clip(
    user_id: str,
    device_uuid: str,
    scene_id: str,
    video_path: str,
    video_type: str = 'before'  # 'before' or 'after'
) -> str:
    """
    ë¹„ë””ì˜¤ í´ë¦½ì„ Supabase Storageì— ì—…ë¡œë“œ
    """
    try:
        supabase = get_supabase_client()

        filename = f"{user_id}/{device_uuid}/{scene_id}_{video_type}.mp4"

        with open(video_path, 'rb') as f:
            video_bytes = f.read()

        response = supabase.storage.from_(BUCKET_FAILURE_VIDEOS).upload(
            path=filename,
            file=video_bytes,
            file_options={"content-type": "video/mp4"}
        )

        public_url = supabase.storage.from_(BUCKET_FAILURE_VIDEOS).get_public_url(filename)

        logger.info(f"[Storage] Video uploaded: {filename}")

        return public_url

    except Exception as e:
        logger.error(f"[Storage] Video upload failed: {str(e)}")
        raise
```

#### 3.2 Supabase DB ì €ì¥ í•¨ìˆ˜

**íŒŒì¼**: `supabase_db.py` (ì¶”ê°€)

```python
"""
Supabase DB ì €ì¥ í•¨ìˆ˜
"""
from typing import Dict
import logging

from supabase_client import get_supabase_client

logger = logging.getLogger("uvicorn.error")

async def save_failure_scene(scene_data: Dict) -> Dict:
    """
    ì‹¤íŒ¨ ì¥ë©´ì„ DBì— ì €ì¥

    Args:
        scene_data: ì¥ë©´ ë°ì´í„°

    Returns:
        ì €ì¥ëœ ë ˆì½”ë“œ
    """
    try:
        supabase = get_supabase_client()

        response = supabase.table('failure_scenes').insert(scene_data).execute()

        logger.info(f"[DB] Failure scene saved: {scene_data['id']}")

        return response.data[0] if response.data else None

    except Exception as e:
        logger.error(f"[DB] Save failed: {str(e)}")
        raise

async def get_failure_scenes(
    user_id: str,
    device_uuid: Optional[str] = None,
    failure_type: Optional[str] = None,
    verified_only: bool = False,
    limit: int = 100
) -> List[Dict]:
    """
    ì‹¤íŒ¨ ì¥ë©´ ì¡°íšŒ
    """
    try:
        supabase = get_supabase_client()

        query = supabase.table('failure_scenes').select('*')
        query = query.eq('user_id', user_id)

        if device_uuid:
            query = query.eq('device_uuid', device_uuid)

        if failure_type:
            query = query.eq('failure_type', failure_type)

        if verified_only:
            query = query.eq('is_verified', True)

        query = query.order('created_at', desc=True).limit(limit)

        response = query.execute()

        return response.data

    except Exception as e:
        logger.error(f"[DB] Query failed: {str(e)}")
        return []
```

#### 3.3 ëª¨ë‹ˆí„°ë§ ì›Œì»¤ í†µí•©

**íŒŒì¼**: `monitoring_worker.py` (ìˆ˜ì •)

```python
# ... (ì´ì „ ì½”ë“œ)

from failure_scene_collector import FailureSceneCollector

class MonitoringWorker:
    def __init__(self, ...):
        # ... (ê¸°ì¡´ ì½”ë“œ)

        # ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ê¸° ì¶”ê°€ â­
        self.scene_collector = FailureSceneCollector(
            device_uuid=device_uuid,
            user_id=user_id,
            print_job_id=print_job_id,
            save_context=True  # ì „í›„ í”„ë ˆì„ ì €ì¥
        )

    async def _monitoring_loop(self):
        while self.is_running:
            try:
                frame = await self.capture.get_frame()

                if frame is None:
                    # ... (ì—ëŸ¬ ì²˜ë¦¬)
                    continue

                # í”„ë ˆì„ì„ ë²„í¼ì— ì¶”ê°€ (ì»¨í…ìŠ¤íŠ¸ìš©) â­
                self.scene_collector.add_frame(frame)

                # AI ë¶„ì„
                detections = await self.ai_service.predict(frame)

                if detections:
                    annotated_frame = self.ai_service.draw_detections(frame, detections)

                    for det in detections:
                        # ê¸°ì¡´ ì²˜ë¦¬
                        await self._process_detection(det, annotated_frame)

                        # ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ â­ NEW
                        await self._collect_failure_scene(
                            frame,
                            annotated_frame,
                            det
                        )

                await asyncio.sleep(self.frame_interval)

            except Exception as e:
                logger.error(f"[Worker] Error: {str(e)}")

    async def _collect_failure_scene(
        self,
        frame: np.ndarray,
        annotated_frame: np.ndarray,
        detection: Dict
    ):
        """
        ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ (NEW)
        """
        try:
            # ì¶œë ¥ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            print_context = await self._get_print_context()

            # ì¥ë©´ ìˆ˜ì§‘
            scene_id = await self.scene_collector.collect_failure_scene(
                current_frame=frame,
                annotated_frame=annotated_frame,
                detection=detection,
                print_context=print_context
            )

            logger.info(f"[Worker] Failure scene collected: {scene_id}")

        except Exception as e:
            logger.error(f"[Worker] Scene collection failed: {str(e)}")

    async def _get_print_context(self) -> Dict:
        """
        í˜„ì¬ ì¶œë ¥ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        (MQTT ë˜ëŠ” DBì—ì„œ)
        """
        # TODO: MQTT í† í”½ì—ì„œ ì‹¤ì‹œê°„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        return {
            'layer_number': 120,
            'progress': 45.5,
            'nozzle_temp': 205.0,
            'bed_temp': 60.0,
            'print_speed': 50.0
        }
```

**ì‘ì—…**:
- [ ] Storage ì—…ë¡œë“œ í•¨ìˆ˜ êµ¬í˜„
- [ ] DB ì €ì¥ í•¨ìˆ˜ êµ¬í˜„
- [ ] ì›Œì»¤ì— ìˆ˜ì§‘ê¸° í†µí•©
- [ ] í…ŒìŠ¤íŠ¸

---

### Phase 4: í”„ë¡ íŠ¸ì—”ë“œ - ì‹¤íŒ¨ ì¥ë©´ ê´€ë¦¬ (Week 3)

#### 4.1 ì‹¤íŒ¨ ì¥ë©´ ëŒ€ì‹œë³´ë“œ

**íŒŒì¼**: `packages/web/src/components/FailureScenesDashboard.tsx`

```typescript
/**
 * ì‹¤íŒ¨ ì¥ë©´ ëŒ€ì‹œë³´ë“œ
 * - ìˆ˜ì§‘ëœ ì‹¤íŒ¨ ì¥ë©´ ëª©ë¡ í‘œì‹œ
 * - ê²€ì¦ UI (ì‚¬ëŒì´ í™•ì¸)
 * - ë°ì´í„°ì…‹ ê´€ë¦¬
 */
import { useState, useEffect } from 'react';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Badge } from '@/components/ui/badge';
import { Button } from '@/components/ui/button';
import { Check, X, Eye, Download } from 'lucide-react';

interface FailureScene {
  id: string;
  failure_type: string;
  confidence: number;
  severity: string;
  original_frame_url: string;
  annotated_frame_url: string;
  before_frames_url?: string;
  frame_timestamp: string;
  is_verified: boolean;
  is_false_positive: boolean;
  layer_number?: number;
  print_progress?: number;
}

export const FailureScenesDashboard = ({ deviceUuid }: { deviceUuid?: string }) => {
  const [scenes, setScenes] = useState<FailureScene[]>([]);
  const [filter, setFilter] = useState<'all' | 'unverified' | 'verified'>('all');

  // ì¥ë©´ ëª©ë¡ ë¡œë“œ
  useEffect(() => {
    fetchScenes();
  }, [deviceUuid, filter]);

  const fetchScenes = async () => {
    const params = new URLSearchParams();
    if (deviceUuid) params.append('device_uuid', deviceUuid);
    if (filter === 'unverified') params.append('unverified_only', 'true');
    if (filter === 'verified') params.append('verified_only', 'true');

    const response = await fetch(`/v1/failure-scenes?${params}`);
    const data = await response.json();
    setScenes(data.scenes || []);
  };

  // ê²€ì¦ (ì •í™•í•¨)
  const handleVerify = async (sceneId: string, isCorrect: boolean) => {
    await fetch(`/v1/failure-scenes/${sceneId}/verify`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        is_correct: isCorrect,
        is_false_positive: !isCorrect
      })
    });

    await fetchScenes();
  };

  // ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°
  const handleExportDataset = async () => {
    const response = await fetch('/v1/failure-scenes/export-dataset', {
      method: 'POST'
    });

    const blob = await response.blob();
    const url = URL.createObjectURL(blob);
    const link = document.createElement('a');
    link.href = url;
    link.download = `failure_dataset_${Date.now()}.zip`;
    link.click();
  };

  return (
    <div className="space-y-4">
      <Card>
        <CardHeader>
          <CardTitle className="flex items-center justify-between">
            <span>Failure Scenes ({scenes.length})</span>
            <div className="flex gap-2">
              <Button onClick={handleExportDataset} size="sm">
                <Download className="w-4 h-4 mr-2" />
                Export Dataset
              </Button>
            </div>
          </CardTitle>
        </CardHeader>
        <CardContent>
          {/* í•„í„° */}
          <div className="flex gap-2 mb-4">
            <Button
              variant={filter === 'all' ? 'default' : 'outline'}
              onClick={() => setFilter('all')}
              size="sm"
            >
              All
            </Button>
            <Button
              variant={filter === 'unverified' ? 'default' : 'outline'}
              onClick={() => setFilter('unverified')}
              size="sm"
            >
              Unverified
            </Button>
            <Button
              variant={filter === 'verified' ? 'default' : 'outline'}
              onClick={() => setFilter('verified')}
              size="sm"
            >
              Verified
            </Button>
          </div>

          {/* ì¥ë©´ ê·¸ë¦¬ë“œ */}
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
            {scenes.map(scene => (
              <Card key={scene.id} className="overflow-hidden">
                {/* ì´ë¯¸ì§€ */}
                <img
                  src={scene.annotated_frame_url}
                  alt={scene.failure_type}
                  className="w-full h-48 object-cover"
                />

                <CardContent className="p-4">
                  {/* íƒ€ì… & ì‹ ë¢°ë„ */}
                  <div className="flex items-center justify-between mb-2">
                    <Badge className={getSeverityColor(scene.severity)}>
                      {scene.failure_type}
                    </Badge>
                    <span className="text-sm text-gray-500">
                      {(scene.confidence * 100).toFixed(1)}%
                    </span>
                  </div>

                  {/* ë©”íƒ€ë°ì´í„° */}
                  <div className="text-xs text-gray-500 space-y-1">
                    {scene.layer_number && (
                      <div>Layer: {scene.layer_number}</div>
                    )}
                    {scene.print_progress && (
                      <div>Progress: {scene.print_progress.toFixed(1)}%</div>
                    )}
                    <div>{new Date(scene.frame_timestamp).toLocaleString()}</div>
                  </div>

                  {/* ê²€ì¦ ë²„íŠ¼ */}
                  {!scene.is_verified && (
                    <div className="flex gap-2 mt-4">
                      <Button
                        size="sm"
                        variant="outline"
                        className="flex-1"
                        onClick={() => handleVerify(scene.id, true)}
                      >
                        <Check className="w-4 h-4 mr-1" />
                        Correct
                      </Button>
                      <Button
                        size="sm"
                        variant="outline"
                        className="flex-1"
                        onClick={() => handleVerify(scene.id, false)}
                      >
                        <X className="w-4 h-4 mr-1" />
                        Wrong
                      </Button>
                    </div>
                  )}

                  {/* ê²€ì¦ë¨ í‘œì‹œ */}
                  {scene.is_verified && (
                    <Badge variant="secondary" className="mt-2">
                      âœ“ Verified
                    </Badge>
                  )}

                  {/* ì›ë³¸/ë¹„ë””ì˜¤ ë³´ê¸° */}
                  <div className="flex gap-2 mt-2">
                    <a
                      href={scene.original_frame_url}
                      target="_blank"
                      className="text-blue-500 text-sm"
                    >
                      Original
                    </a>
                    {scene.before_frames_url && (
                      <a
                        href={scene.before_frames_url}
                        target="_blank"
                        className="text-blue-500 text-sm"
                      >
                        Video
                      </a>
                    )}
                  </div>
                </CardContent>
              </Card>
            ))}
          </div>
        </CardContent>
      </Card>
    </div>
  );
};

function getSeverityColor(severity: string) {
  switch (severity) {
    case 'critical': return 'bg-red-500';
    case 'high': return 'bg-orange-500';
    case 'medium': return 'bg-yellow-500';
    default: return 'bg-gray-500';
  }
}
```

#### 4.2 ì‹¤íŒ¨ ì¥ë©´ API

**íŒŒì¼**: `main.py` (ì¶”ê°€)

```python
"""
ì‹¤íŒ¨ ì¥ë©´ ê´€ë¦¬ API
"""
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import zipfile
import io

router = APIRouter(prefix="/v1/failure-scenes", tags=["Failure Scenes"])

class VerifySceneRequest(BaseModel):
    is_correct: bool
    is_false_positive: bool
    corrected_type: Optional[str] = None

@router.get("/")
async def get_failure_scenes(
    user_id: str,
    device_uuid: Optional[str] = None,
    failure_type: Optional[str] = None,
    unverified_only: bool = False,
    verified_only: bool = False,
    limit: int = 100
):
    """ì‹¤íŒ¨ ì¥ë©´ ëª©ë¡ ì¡°íšŒ"""
    from supabase_db import get_failure_scenes

    scenes = await get_failure_scenes(
        user_id=user_id,
        device_uuid=device_uuid,
        failure_type=failure_type,
        verified_only=verified_only,
        limit=limit
    )

    if unverified_only:
        scenes = [s for s in scenes if not s['is_verified']]

    return {"scenes": scenes, "total": len(scenes)}

@router.post("/{scene_id}/verify")
async def verify_scene(scene_id: str, request: VerifySceneRequest):
    """
    ì‹¤íŒ¨ ì¥ë©´ ê²€ì¦
    - ì‚¬ëŒì´ í™•ì¸í•˜ì—¬ ì •í™•ì„± í‘œì‹œ
    """
    from supabase_client import get_supabase_client

    supabase = get_supabase_client()

    update_data = {
        'is_verified': True,
        'is_false_positive': request.is_false_positive,
        'verified_at': 'NOW()',
        'updated_at': 'NOW()'
    }

    if request.corrected_type:
        update_data['corrected_type'] = request.corrected_type

    response = supabase.table('failure_scenes').update(update_data).eq('id', scene_id).execute()

    return {"status": "ok", "scene_id": scene_id}

@router.post("/export-dataset")
async def export_dataset(
    user_id: str,
    verified_only: bool = True
):
    """
    ê²€ì¦ëœ ì‹¤íŒ¨ ì¥ë©´ì„ ë°ì´í„°ì…‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
    - YOLO í˜•ì‹ (images/ + labels/)
    - í–¥í›„ ì»¤ìŠ¤í…€ í•™ìŠµì— ì‚¬ìš©
    """
    from supabase_db import get_failure_scenes
    import requests

    # ê²€ì¦ëœ ì¥ë©´ë§Œ ê°€ì ¸ì˜¤ê¸°
    scenes = await get_failure_scenes(
        user_id=user_id,
        verified_only=verified_only,
        limit=1000
    )

    # ZIP íŒŒì¼ ìƒì„±
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
        # dataset.yaml ìƒì„±
        yaml_content = """
path: ./dataset
train: images/train
val: images/val
names:
  0: spaghetti
  1: warping
  2: layer_separation
  3: clogging
  4: support_failure
  5: first_layer_fail
"""
        zip_file.writestr('dataset.yaml', yaml_content)

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì¶”ê°€
        for i, scene in enumerate(scenes):
            # ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            img_response = requests.get(scene['original_frame_url'])
            img_data = img_response.content

            split = 'train' if i % 10 < 8 else 'val'  # 80% train, 20% val

            zip_file.writestr(
                f"images/{split}/{scene['id']}.jpg",
                img_data
            )

            # TODO: ë°”ìš´ë”© ë°•ìŠ¤ê°€ ìˆìœ¼ë©´ ë¼ë²¨ íŒŒì¼ ìƒì„±
            # labels/{split}/{scene_id}.txt

    zip_buffer.seek(0)

    from fastapi.responses import StreamingResponse

    return StreamingResponse(
        zip_buffer,
        media_type='application/zip',
        headers={'Content-Disposition': f'attachment; filename=failure_dataset.zip'}
    )

@router.get("/stats")
async def get_failure_stats(user_id: str, time_range: str = "7d"):
    """
    ì‹¤íŒ¨ ì¥ë©´ í†µê³„
    - íƒ€ì…ë³„ ë¹ˆë„
    - ê²€ì¦ ìƒíƒœ
    """
    from supabase_client import get_supabase_client

    supabase = get_supabase_client()

    # íƒ€ì…ë³„ ì¹´ìš´íŠ¸
    response = supabase.rpc('get_failure_type_counts', {'user_id_param': user_id}).execute()

    return {
        "total_scenes": response.data.get('total', 0),
        "verified": response.data.get('verified', 0),
        "type_distribution": response.data.get('by_type', {}),
        "severity_distribution": response.data.get('by_severity', {})
    }
```

**ì‘ì—…**:
- [ ] ì‹¤íŒ¨ ì¥ë©´ ëŒ€ì‹œë³´ë“œ UI
- [ ] ê²€ì¦ UI êµ¬í˜„
- [ ] ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸° API
- [ ] í†µê³„ API

---

### Phase 5: ë°°í¬ ë° í…ŒìŠ¤íŠ¸ (Week 4)

#### 5.1 requirements.txt ì—…ë°ì´íŠ¸

```txt
fastapi==0.115.0
uvicorn[standard]==0.31.0
httpx==0.28.1
python-multipart==0.0.9
python-dotenv==1.0.1
pydantic==2.12.4

# AI & Vision
torch==2.1.0
torchvision==0.16.0
opencv-python==4.8.1.78
Pillow==10.1.0
numpy==1.24.3

# Spaghetti Detective (ì‚¬ì „í•™ìŠµ ëª¨ë¸) â­
# git+https://github.com/TheSpaghettiDetective/ml_api.git

# Database & Storage
supabase==2.24.0
websockets==15.0.1
paho-mqtt==1.6.1

# Utils
requests==2.31.0
python-jose[cryptography]==3.3.0
```

#### 5.2 Docker ë°°í¬

**Dockerfile**:

```dockerfile
FROM python:3.11-slim

# CUDA ì§€ì› (GPU ì‚¬ìš© ì‹œ)
# FROM nvidia/cuda:12.1.0-runtime-ubuntu22.04

WORKDIR /app

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    git \
    && rm -rf /var/lib/apt/lists/*

# Python íŒ¨í‚¤ì§€
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Spaghetti Detective ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
RUN python -c "from setup_model import download_spaghetti_detective_model; download_spaghetti_detective_model()"

# ì†ŒìŠ¤ ì½”ë“œ
COPY *.py /app/

EXPOSE 7000

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "7000"]
```

**ì‘ì—…**:
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ
- [ ] GPU ì§€ì› ì„¤ì •
- [ ] í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí¬
- [ ] í”„ë¡œë•ì…˜ ë°°í¬

---

## íƒ€ì„ë¼ì¸ ìš”ì•½ (4ì£¼ë¡œ ë‹¨ì¶•!)

| Week | Phase | ì£¼ìš” ì‘ì—… | ì‚°ì¶œë¬¼ |
|------|-------|----------|--------|
| 1 | Phase 1-2 | ëª¨ë¸ í†µí•© + ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ | AI ì¶”ë¡  ì„œë¹„ìŠ¤, DB ìŠ¤í‚¤ë§ˆ |
| 2 | Phase 3 | API í†µí•© | ì™„ì „í•œ ë°±ì—”ë“œ API |
| 3 | Phase 4 | í”„ë¡ íŠ¸ì—”ë“œ | ëŒ€ì‹œë³´ë“œ UI |
| 4 | Phase 5 | ë°°í¬ & í…ŒìŠ¤íŠ¸ | í”„ë¡œë•ì…˜ ì‹œìŠ¤í…œ |

**ì´ ì˜ˆìƒ ê¸°ê°„**: 4ì£¼ (ì•½ 1ê°œì›”) âš¡

---

## ğŸ¯ v2.0 í•µì‹¬ ê°œì„ ì‚¬í•­

### 1. **ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥** âœ…
- âŒ í•™ìŠµ ë¶ˆí•„ìš”
- âœ… Spaghetti Detective ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš©
- âš¡ ê°œë°œ ê¸°ê°„ 12ì£¼ â†’ 4ì£¼

### 2. **ì‹¤íŒ¨ ì¥ë©´ ìë™ ìˆ˜ì§‘** â­
- ê°ì§€ëœ ë¶ˆëŸ‰ í”„ë ˆì„ ìë™ ì €ì¥
- ì „í›„ ì»¨í…ìŠ¤íŠ¸ (ë¹„ë””ì˜¤ í´ë¦½)
- ì¶œë ¥ ìƒíƒœ ë©”íƒ€ë°ì´í„° (ì˜¨ë„, ì†ë„, ë ˆì´ì–´ ë“±)

### 3. **ë°ì´í„°ì…‹ ìë™ êµ¬ì¶•** ğŸ“Š
- ì‹¤ì „ ë°ì´í„° ì¶•ì 
- ì‚¬ëŒ ê²€ì¦ UI
- YOLO í˜•ì‹ ë‚´ë³´ë‚´ê¸°
- í–¥í›„ ì»¤ìŠ¤í…€ í•™ìŠµ ê°€ëŠ¥

### 4. **ë¹„ìš© ì ˆê°** ğŸ’°
- ë¼ë²¨ë§ ì‘ì—… ë¶ˆí•„ìš”
- GPU ì„œë²„ í•™ìŠµ ë¹„ìš© ì—†ìŒ
- ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê°œë°œ í™˜ê²½
- [ ] Python 3.11 ì„¤ì¹˜
- [ ] PyTorch ì„¤ì¹˜
- [ ] OpenCV ì„¤ì¹˜
- [ ] Spaghetti Detective ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

### ì¸í”„ë¼
- [ ] Supabase í”„ë¡œì íŠ¸ ìƒì„±
- [ ] Storage ë²„í‚· ìƒì„± (failure_frames, failure_videos)
- [ ] DB í…Œì´ë¸” ìƒì„± (failure_scenes)

### ë°±ì—”ë“œ
- [ ] AI ì¶”ë¡  ì„œë¹„ìŠ¤ êµ¬í˜„
- [ ] ì‹¤íŒ¨ ì¥ë©´ ìˆ˜ì§‘ê¸° êµ¬í˜„
- [ ] API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] MQTT ì•Œë¦¼ í†µí•©

### í”„ë¡ íŠ¸ì—”ë“œ
- [ ] ì‹¤íŒ¨ ì¥ë©´ ëŒ€ì‹œë³´ë“œ
- [ ] ê²€ì¦ UI
- [ ] ë°ì´í„°ì…‹ ë‚´ë³´ë‚´ê¸°

### ë°°í¬
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ
- [ ] í…ŒìŠ¤íŠ¸
- [ ] í”„ë¡œë•ì…˜ ë°°í¬

---

**ë¬¸ì„œ ì‘ì„±ì¼**: 2025-01-26
**ë²„ì „**: 2.0 (Spaghetti Detective + Auto-Collection)
**ì‘ì„±ì**: Claude AI Assistant
