"""
Issue Validator - ë£° ì—”ì§„ ê°ì§€ ì´ìŠˆì˜ LLM ê²€ì¦

ë£° ì—”ì§„ì—ì„œ ê°ì§€ëœ ì´ìŠˆê°€ ì‹¤ì œ ë¬¸ì œì¸ì§€ ì˜¤íƒ(false positive)ì¸ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
ì£¼ë³€ G-code ì»¨í…ìŠ¤íŠ¸ (ì•ë’¤ 50ì¤„)ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì¢… íŒì •í•©ë‹ˆë‹¤.
"""
import json
import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

from .client import get_llm_client_lite
from .language import get_language_instruction

logger = logging.getLogger(__name__)


ISSUE_VALIDATION_PROMPT = """ë‹¹ì‹ ì€ 3D í”„ë¦°íŒ… G-code ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì´ìŠˆê°€ ì‹¤ì œ ë¬¸ì œì¸ì§€, ì•„ë‹ˆë©´ ì˜¤íƒ(false positive)ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

## ê°ì§€ëœ ì´ìŠˆ
- ìœ í˜•: {issue_type}
- ë¼ì¸: {line_number}
- ì„¤ëª…: {description}
- ì‹¬ê°ë„: {severity}

## G-code ì»¨í…ìŠ¤íŠ¸ (ë¬¸ì œ ë¼ì¸ ì£¼ë³€ ì½”ë“œ)
```gcode
{gcode_context}
```

## ğŸ”§ ì œì¡°ì‚¬ë³„ ì»¤ìŠ¤í…€ ì½”ë“œ ì£¼ì˜ì‚¬í•­
ë‹¤ìŒ íŒ¨í„´ì€ **ì •ìƒ ì½”ë“œ**ì…ë‹ˆë‹¤. ì˜¤íƒìœ¼ë¡œ íŒì •í•´ì•¼ í•©ë‹ˆë‹¤:

1. **Bambu Lab / OrcaSlicer H-ì½”ë“œ**:
   - `M104 S25 H220` â†’ H=ì‹¤ì œì˜¨ë„, S=ëŒ€ê¸°ì‹œê°„ (ì •ìƒ)
   - `M109 S25 H220` â†’ H=ì‹¤ì œì˜¨ë„, S=ëŒ€ê¸°ì‹œê°„ (ì •ìƒ)
   - `M104 H210` â†’ H=ì‹¤ì œì˜¨ë„ (ì •ìƒ)

2. **Klipper ë§¤í¬ë¡œ**:
   - `PRINT_START`, `SET_HEATER_TEMPERATURE` ë“± â†’ ì •ìƒ

3. **ì˜¨ë„ ëŒ€ê¸° ìˆœì„œ**:
   - `M109 S220` (ì˜¨ë„ ì„¤ì • + ëŒ€ê¸°) ì´í›„ ì••ì¶œ â†’ ì •ìƒ
   - M109ê°€ M104ë³´ë‹¤ ë¨¼ì € ë‚˜ì™€ë„, ì••ì¶œ ì „ì— ëŒ€ê¸°í–ˆìœ¼ë©´ â†’ ì •ìƒ

4. **END_GCODE ì„¹ì…˜**:
   - ì¶œë ¥ ì¢…ë£Œ í›„ `M104 S0` (ì˜¨ë„ 0)ì€ ì •ìƒ ì¢…ë£Œ ì½”ë“œ

## íŒì • ê¸°ì¤€
- **ì‹¤ì œ ë¬¸ì œ**: ì••ì¶œ ì‹œì ì— ë…¸ì¦ ì˜¨ë„ê°€ ë¶€ì¡±í•˜ê±°ë‚˜, ì¶œë ¥ ì¤‘ì— ë¹„ì •ìƒì ìœ¼ë¡œ ì˜¨ë„ê°€ 0ì´ ë˜ëŠ” ê²½ìš°
- **ì˜¤íƒ**: H-ì½”ë“œ ì‚¬ìš©, M109 ëŒ€ê¸° í›„ ì••ì¶œ, END_GCODEì—ì„œ ì˜¨ë„ 0 ì„¤ì • ë“±

## ì‘ë‹µ í˜•ì‹ (JSONë§Œ)
{{
  "is_valid_issue": true/false,
  "confidence": 0.0-1.0,
  "reasoning": "íŒì • ì´ìœ  (100ì ì´ë‚´)",
  "corrected_severity": "critical|high|medium|low|info|none"
}}

JSONë§Œ ì‘ë‹µí•˜ì„¸ìš”:
"""


@dataclass
class ValidationResult:
    """ê²€ì¦ ê²°ê³¼"""
    is_valid_issue: bool  # True: ì‹¤ì œ ë¬¸ì œ, False: ì˜¤íƒ
    confidence: float
    reasoning: str
    corrected_severity: str


async def validate_single_issue(
    issue: Dict[str, Any],
    gcode_context: str,
    language: str = "ko"
) -> Tuple[ValidationResult, Dict[str, int]]:
    """
    ë‹¨ì¼ ì´ìŠˆ ê²€ì¦

    Args:
        issue: ì´ìŠˆ ì •ë³´
        gcode_context: ì£¼ë³€ G-code (ì•ë’¤ 50ì¤„)
        language: ì‘ë‹µ ì–¸ì–´

    Returns:
        (ValidationResult, token_usage)
    """
    llm = get_llm_client_lite(max_output_tokens=512)

    issue_type = issue.get("issue_type") or issue.get("type", "unknown")
    line_number = issue.get("line") or issue.get("event_line_index", 0)
    description = issue.get("description", "")
    severity = issue.get("severity", "medium")

    prompt_text = ISSUE_VALIDATION_PROMPT.format(
        issue_type=issue_type,
        line_number=line_number,
        description=description,
        severity=severity,
        gcode_context=gcode_context
    )

    # ì–¸ì–´ ì„¤ì •
    language_instruction = get_language_instruction(language)
    prompt_text = f"{language_instruction}\n\n{prompt_text}"

    tokens = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}

    try:
        response = await llm.ainvoke(prompt_text)
        output_text = response.content if hasattr(response, 'content') else str(response)

        # í† í° ì‚¬ìš©ëŸ‰
        if hasattr(response, 'usage_metadata'):
            tokens["input_tokens"] = getattr(response.usage_metadata, 'input_tokens', 0)
            tokens["output_tokens"] = getattr(response.usage_metadata, 'output_tokens', 0)
            tokens["total_tokens"] = tokens["input_tokens"] + tokens["output_tokens"]

        # JSON íŒŒì‹±
        json_text = output_text
        if "```json" in output_text:
            json_text = output_text.split("```json")[1].split("```")[0]
        elif "```" in output_text:
            json_text = output_text.split("```")[1].split("```")[0]

        result_dict = json.loads(json_text.strip())

        return ValidationResult(
            is_valid_issue=result_dict.get("is_valid_issue", True),
            confidence=result_dict.get("confidence", 0.5),
            reasoning=result_dict.get("reasoning", ""),
            corrected_severity=result_dict.get("corrected_severity", severity)
        ), tokens

    except json.JSONDecodeError as e:
        logger.warning(f"[IssueValidator] JSON parse error: {e}")
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€ (ì•ˆì „í•˜ê²Œ ì‹¤ì œ ë¬¸ì œë¡œ ê°„ì£¼)
        return ValidationResult(
            is_valid_issue=True,
            confidence=0.5,
            reasoning="ê²€ì¦ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨",
            corrected_severity=severity
        ), tokens

    except Exception as e:
        logger.error(f"[IssueValidator] Validation error: {e}")
        return ValidationResult(
            is_valid_issue=True,
            confidence=0.5,
            reasoning=f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}",
            corrected_severity=severity
        ), tokens


def extract_context_for_validation(
    parsed_lines: list,
    line_number: int,
    context_lines: int = 50
) -> str:
    """
    ê²€ì¦ìš© G-code ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì•ë’¤ 50ì¤„)

    Args:
        parsed_lines: íŒŒì‹±ëœ G-code ë¼ì¸ë“¤
        line_number: ëŒ€ìƒ ë¼ì¸ ë²ˆí˜¸ (1-based)
        context_lines: ì•ë’¤ë¡œ í¬í•¨í•  ë¼ì¸ ìˆ˜

    Returns:
        ë¼ì¸ ë²ˆí˜¸ê°€ í¬í•¨ëœ G-code ì»¨í…ìŠ¤íŠ¸
    """
    if not line_number or not parsed_lines:
        return ""

    total_lines = len(parsed_lines)
    target_idx = line_number - 1  # 0-based

    start_idx = max(0, target_idx - context_lines)
    end_idx = min(total_lines, target_idx + context_lines + 1)

    context_parts = []
    for i in range(start_idx, end_idx):
        line_num = i + 1
        line_content = parsed_lines[i].raw.strip() if hasattr(parsed_lines[i], 'raw') else str(parsed_lines[i])

        if i == target_idx:
            context_parts.append(f">>> {line_num}: {line_content}  <<< [ë¬¸ì œ ë¼ì¸]")
        else:
            context_parts.append(f"    {line_num}: {line_content}")

    return '\n'.join(context_parts)


async def validate_issues(
    issues: List[Dict[str, Any]],
    parsed_lines: list,
    language: str = "ko",
    context_lines: int = 50
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], Dict[str, int]]:
    """
    ì—¬ëŸ¬ ì´ìŠˆë¥¼ LLMìœ¼ë¡œ ê²€ì¦í•˜ì—¬ ì‹¤ì œ ë¬¸ì œë§Œ í•„í„°ë§

    Args:
        issues: ê²€ì¦í•  ì´ìŠˆ ëª©ë¡
        parsed_lines: íŒŒì‹±ëœ G-code ë¼ì¸ë“¤
        language: ì‘ë‹µ ì–¸ì–´
        context_lines: ì»¨í…ìŠ¤íŠ¸ ë¼ì¸ ìˆ˜ (ê¸°ë³¸ 50)

    Returns:
        (validated_issues, filtered_issues, total_tokens)
        - validated_issues: ì‹¤ì œ ë¬¸ì œë¡œ í™•ì¸ëœ ì´ìŠˆ
        - filtered_issues: ì˜¤íƒìœ¼ë¡œ ì œê±°ëœ ì´ìŠˆ
        - total_tokens: ì´ í† í° ì‚¬ìš©ëŸ‰
    """
    if not issues:
        return [], [], {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}

    validated_issues = []
    filtered_issues = []
    total_tokens = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}

    for issue in issues:
        line_number = issue.get("line") or issue.get("event_line_index")

        # ë¼ì¸ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ê²€ì¦ ì—†ì´ í†µê³¼ (ì•ˆì „í•˜ê²Œ ì´ìŠˆ ìœ ì§€)
        if not line_number:
            validated_issues.append({
                **issue,
                "validation": {
                    "validated": True,
                    "confidence": 0.5,
                    "reasoning": "ë¼ì¸ ë²ˆí˜¸ ì—†ìŒ - ê²€ì¦ ìƒëµ"
                }
            })
            continue

        # G-code ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        gcode_context = extract_context_for_validation(parsed_lines, line_number, context_lines)

        # LLM ê²€ì¦
        result, tokens = await validate_single_issue(issue, gcode_context, language)

        # í† í° í•©ì‚°
        total_tokens["input_tokens"] += tokens["input_tokens"]
        total_tokens["output_tokens"] += tokens["output_tokens"]
        total_tokens["total_tokens"] += tokens["total_tokens"]

        if result.is_valid_issue:
            # ì‹¤ì œ ë¬¸ì œ: ì‹¬ê°ë„ ìˆ˜ì • ì ìš©
            validated_issue = {
                **issue,
                "severity": result.corrected_severity if result.corrected_severity != "none" else issue.get("severity"),
                "validation": {
                    "validated": True,
                    "confidence": result.confidence,
                    "reasoning": result.reasoning
                }
            }
            validated_issues.append(validated_issue)
            logger.info(f"[IssueValidator] Issue VALIDATED (line {line_number}): {result.reasoning}")
        else:
            # ì˜¤íƒ: ì œê±° ëª©ë¡ì— ì¶”ê°€
            filtered_issue = {
                **issue,
                "validation": {
                    "validated": False,
                    "is_false_positive": True,
                    "confidence": result.confidence,
                    "reasoning": result.reasoning
                }
            }
            filtered_issues.append(filtered_issue)
            logger.info(f"[IssueValidator] Issue FILTERED as false positive (line {line_number}): {result.reasoning}")

    logger.info(
        f"[IssueValidator] Validation complete: "
        f"{len(validated_issues)} valid, {len(filtered_issues)} filtered"
    )

    return validated_issues, filtered_issues, total_tokens
