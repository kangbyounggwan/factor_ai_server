"""
íŠ¸ëŸ¬ë¸”ìŠˆíŒ… API í…ŒìŠ¤íŠ¸ ë²¤ì¹˜
ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì œ ì§„ë‹¨ í…ŒìŠ¤íŠ¸
"""
import asyncio
import base64
import json
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from dotenv import load_dotenv
load_dotenv()

from gcode_analyzer.troubleshoot.image_analyzer import ImageAnalyzer
from gcode_analyzer.troubleshoot.perplexity_searcher import PerplexitySearcher
from gcode_analyzer.troubleshoot.structured_editor import StructuredEditor
from gcode_analyzer.troubleshoot.models import UserPlan, ProblemType, SearchDecision


async def run_test(image_path: str, symptom_text: str):
    """
    íŠ¸ëŸ¬ë¸”ìŠˆíŒ… íë¦„ í…ŒìŠ¤íŠ¸
    """
    print("=" * 60)
    print("ğŸ” 3D í”„ë¦°í„° ë¬¸ì œ ì§„ë‹¨ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    print(f"\nğŸ“· ì´ë¯¸ì§€ ë¡œë“œ: {image_path}")
    with open(image_path, "rb") as f:
        image_data = base64.b64encode(f.read()).decode("utf-8")

    results = {
        "input": {
            "image_path": image_path,
            "symptom_text": symptom_text
        },
        "step1_image_analysis": None,
        "step2_search": None,
        "step3_solution": None
    }

    # ================================================================
    # 1ë‹¨ê³„: Vision + ì§ˆë¬¸ ì¦ê°• + Gate
    # ================================================================
    print("\n" + "=" * 60)
    print("ğŸ“¸ 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ + ì§ˆë¬¸ ì¦ê°• + Gate íŒë‹¨")
    print("=" * 60)

    analyzer = ImageAnalyzer(language="ko")
    image_analysis = await analyzer.analyze_images(
        images=[image_data],
        symptom_text=symptom_text
    )

    results["step1_image_analysis"] = {
        "detected_problems": [p.value for p in image_analysis.detected_problems],
        "confidence_scores": image_analysis.confidence_scores,
        "description": image_analysis.description,
        "visual_evidence": image_analysis.visual_evidence,
        "augmented_query": image_analysis.augmented_query,
        "follow_up_questions": image_analysis.follow_up_questions,
        "specific_symptoms": image_analysis.specific_symptoms,
        "needs_search": image_analysis.needs_search.value,
        "search_skip_reason": image_analysis.search_skip_reason,
        "internal_solution": image_analysis.internal_solution
    }

    print(f"\nğŸ” ê°ì§€ëœ ë¬¸ì œ: {[p.value for p in image_analysis.detected_problems]}")
    print(f"ğŸ“Š í™•ì‹ ë„: {image_analysis.confidence_scores}")
    print(f"\nğŸ“ ì„¤ëª…:\n{image_analysis.description}")
    print(f"\nğŸ” ì¦ê°•ëœ ê²€ìƒ‰ ì¿¼ë¦¬:\n{image_analysis.augmented_query}")
    print(f"\nâ“ ì¶”ê°€ ì§ˆë¬¸:")
    for i, q in enumerate(image_analysis.follow_up_questions, 1):
        print(f"   {i}. {q}")
    print(f"\nğŸš¦ Gate íŒë‹¨: {image_analysis.needs_search.value}")
    if image_analysis.search_skip_reason:
        print(f"   ìŠ¤í‚µ ì´ìœ : {image_analysis.search_skip_reason}")
    if image_analysis.internal_solution:
        print(f"   ë‚´ë¶€ ì†”ë£¨ì…˜: {image_analysis.internal_solution[:200]}...")

    # ================================================================
    # 2ë‹¨ê³„: Perplexity ê²€ìƒ‰ (Gate í†µê³¼ ì‹œ)
    # ================================================================
    print("\n" + "=" * 60)
    print("ğŸ” 2ë‹¨ê³„: Perplexity ê²€ìƒ‰ (Evidence ìˆ˜ì§‘)")
    print("=" * 60)

    if image_analysis.needs_search == SearchDecision.NOT_NEEDED:
        print("\nâ­ï¸ ê²€ìƒ‰ ìŠ¤í‚µ - ë‚´ë¶€ KBë¡œ í•´ê²° ê°€ëŠ¥")
        from gcode_analyzer.troubleshoot.models import PerplexitySearchResult
        search_result = PerplexitySearchResult(
            query=image_analysis.augmented_query,
            findings=[],
            citations=[],
            summary=image_analysis.internal_solution,
            tokens_used=0
        )
        results["step2_search"] = {
            "skipped": True,
            "reason": image_analysis.search_skip_reason,
            "internal_solution": image_analysis.internal_solution
        }
    else:
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {image_analysis.augmented_query}")

        searcher = PerplexitySearcher(user_plan=UserPlan.FREE, language="ko")
        problem_type = image_analysis.detected_problems[0] if image_analysis.detected_problems else ProblemType.UNKNOWN

        search_result = await searcher.search(
            augmented_query=image_analysis.augmented_query,
            problem_type=problem_type
        )

        results["step2_search"] = {
            "skipped": False,
            "query": search_result.query,
            "findings": [
                {
                    "fact": e.fact,
                    "source_url": e.source_url,
                    "source_title": e.source_title
                }
                for e in search_result.findings
            ],
            "citations": search_result.citations,
            "summary": search_result.summary,
            "tokens_used": search_result.tokens_used
        }

        print(f"\nğŸ“š ê²€ìƒ‰ ê²°ê³¼: {len(search_result.findings)}ê°œ Evidence ë°œê²¬")
        for i, evidence in enumerate(search_result.findings[:5], 1):
            print(f"\n   {i}. {evidence.fact[:100]}...")
            print(f"      ì¶œì²˜: {evidence.source_url}")

        if search_result.citations:
            print(f"\nğŸ“ ì¸ìš© URL ({len(search_result.citations)}ê°œ):")
            for url in search_result.citations[:5]:
                print(f"   - {url}")

    # ================================================================
    # 3ë‹¨ê³„: êµ¬ì¡°í™” í¸ì§‘
    # ================================================================
    print("\n" + "=" * 60)
    print("ğŸ“‹ 3ë‹¨ê³„: êµ¬ì¡°í™” í¸ì§‘ (Evidence ê¸°ë°˜)")
    print("=" * 60)

    editor = StructuredEditor(language="ko")
    structured_diagnosis = await editor.edit(
        image_analysis=image_analysis,
        search_result=search_result,
        symptom_text=symptom_text,
        problem_type=problem_type if 'problem_type' in dir() else ProblemType.UNKNOWN
    )

    results["step3_solution"] = {
        "observed": structured_diagnosis.observed,
        "likely_causes": structured_diagnosis.likely_causes,
        "immediate_checks": structured_diagnosis.immediate_checks,
        "solutions": structured_diagnosis.solutions,
        "need_more_info": structured_diagnosis.need_more_info
    }

    print(f"\nğŸ“ ê´€ì°°ëœ ì¦ìƒ:\n{structured_diagnosis.observed}")

    print(f"\nğŸ¯ ê°€ëŠ¥í•œ ì›ì¸:")
    for cause in structured_diagnosis.likely_causes:
        print(f"   - {cause.get('cause', 'N/A')}")
        print(f"     ì¶œì²˜: {cause.get('source', 'N/A')}")

    print(f"\nâœ… ì¦‰ì‹œ í™•ì¸í•  ì‚¬í•­:")
    for check in structured_diagnosis.immediate_checks:
        print(f"   - {check}")

    print(f"\nğŸ”§ í•´ê²°ì±…:")
    for sol in structured_diagnosis.solutions:
        print(f"\n   ğŸ“Œ {sol.get('title', 'N/A')}")
        for step in sol.get('steps', []):
            print(f"      - {step}")
        print(f"      ì¶œì²˜: {sol.get('source', 'N/A')}")

    print(f"\nâ“ ì¶”ê°€ ì •ë³´ í•„ìš”:")
    for info in structured_diagnosis.need_more_info:
        print(f"   - {info}")

    return results


def save_results_as_markdown(results: dict, output_path: str):
    """ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥"""
    md_content = f"""# ğŸ” 3D í”„ë¦°í„° ë¬¸ì œ ì§„ë‹¨ ê²°ê³¼

## ğŸ“¥ ì…ë ¥ ì •ë³´
- **ì´ë¯¸ì§€**: `{results['input']['image_path']}`
- **ì¦ìƒ í…ìŠ¤íŠ¸**: "{results['input']['symptom_text']}"

---

## ğŸ“¸ 1ë‹¨ê³„: ì´ë¯¸ì§€ ë¶„ì„ + ì§ˆë¬¸ ì¦ê°•

### ê°ì§€ëœ ë¬¸ì œ
"""

    step1 = results['step1_image_analysis']
    for prob in step1['detected_problems']:
        confidence = step1['confidence_scores'].get(prob, 'N/A')
        md_content += f"- **{prob}** (í™•ì‹ ë„: {confidence})\n"

    md_content += f"""
### ì´ë¯¸ì§€ ë¶„ì„ ì„¤ëª…
{step1['description']}

### ì‹œê°ì  ì¦ê±°
"""
    for evidence in step1['visual_evidence']:
        md_content += f"- {evidence}\n"

    md_content += f"""
### ğŸ” ì¦ê°•ëœ ê²€ìƒ‰ ì¿¼ë¦¬ (Augmented Query)
```
{step1['augmented_query']}
```

### â“ ì¶”ê°€ ì§ˆë¬¸ (Follow-up Questions)
"""
    for i, q in enumerate(step1['follow_up_questions'], 1):
        md_content += f"{i}. {q}\n"

    md_content += f"""
### ğŸš¦ Gate íŒë‹¨
- **ê²€ìƒ‰ í•„ìš” ì—¬ë¶€**: `{step1['needs_search']}`
"""
    if step1['search_skip_reason']:
        md_content += f"- **ìŠ¤í‚µ ì´ìœ **: {step1['search_skip_reason']}\n"
    if step1['internal_solution']:
        md_content += f"- **ë‚´ë¶€ ì†”ë£¨ì…˜**: {step1['internal_solution']}\n"

    md_content += """
---

## ğŸ” 2ë‹¨ê³„: Perplexity ê²€ìƒ‰ ê²°ê³¼

"""

    step2 = results['step2_search']
    if step2.get('skipped'):
        md_content += f"""### â­ï¸ ê²€ìƒ‰ ìŠ¤í‚µë¨
- **ì´ìœ **: {step2.get('reason', 'N/A')}
- **ë‚´ë¶€ ì†”ë£¨ì…˜ ì‚¬ìš©**: {step2.get('internal_solution', 'N/A')[:500]}...
"""
    else:
        md_content += f"""### ê²€ìƒ‰ ì¿¼ë¦¬
```
{step2['query']}
```

### ğŸ“š ê²€ìƒ‰ëœ Evidence ({len(step2['findings'])}ê°œ)

| # | ì‚¬ì‹¤/ì •ë³´ | ì¶œì²˜ |
|---|----------|------|
"""
        for i, finding in enumerate(step2['findings'], 1):
            fact = finding['fact'][:100].replace('\n', ' ') + '...' if len(finding['fact']) > 100 else finding['fact'].replace('\n', ' ')
            url = finding['source_url']
            title = finding.get('source_title', '-')
            md_content += f"| {i} | {fact} | [{title}]({url}) |\n"

        md_content += f"""
### ğŸ“ ì¸ìš© URL (Citations)
"""
        for url in step2.get('citations', []):
            md_content += f"- {url}\n"

        md_content += f"""
### ğŸ“ ê²€ìƒ‰ ìš”ì•½ (Raw)
```
{step2['summary'][:2000]}
```

### í† í° ì‚¬ìš©ëŸ‰
- **ì´ í† í°**: {step2['tokens_used']}
"""

    md_content += """
---

## ğŸ“‹ 3ë‹¨ê³„: êµ¬ì¡°í™”ëœ ì§„ë‹¨ ê²°ê³¼

"""

    step3 = results['step3_solution']
    md_content += f"""### ğŸ“ ê´€ì°°ëœ ì¦ìƒ
{step3['observed']}

### ğŸ¯ ê°€ëŠ¥í•œ ì›ì¸
"""
    for cause in step3['likely_causes']:
        md_content += f"- **{cause.get('cause', 'N/A')}**\n"
        md_content += f"  - ì¶œì²˜: {cause.get('source', 'N/A')}\n"

    md_content += """
### âœ… ì¦‰ì‹œ í™•ì¸í•  ì‚¬í•­
"""
    for check in step3['immediate_checks']:
        md_content += f"- {check}\n"

    md_content += """
### ğŸ”§ í•´ê²°ì±…
"""
    for i, sol in enumerate(step3['solutions'], 1):
        md_content += f"""
#### {i}. {sol.get('title', 'N/A')}
- **ë‚œì´ë„**: {sol.get('difficulty', 'N/A')}
- **ì¶œì²˜**: {sol.get('source', 'N/A')}
- **ë‹¨ê³„**:
"""
        for step in sol.get('steps', []):
            md_content += f"  1. {step}\n"

    md_content += """
### â“ ì¶”ê°€ë¡œ í•„ìš”í•œ ì •ë³´
"""
    for info in step3['need_more_info']:
        md_content += f"- {info}\n"

    md_content += """
---

## ğŸ“Š Raw JSON ê²°ê³¼

<details>
<summary>ì „ì²´ JSON ë°ì´í„° ë³´ê¸°</summary>

```json
""" + json.dumps(results, indent=2, ensure_ascii=False) + """
```

</details>
"""

    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"\nâœ… ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")


async def main():
    import sys

    # ëª…ë ¹í–‰ ì¸ìë¡œ ì´ë¯¸ì§€ ê²½ë¡œ ë°›ê¸°
    if len(sys.argv) > 1:
        test_image = sys.argv[1]
    else:
        # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
        test_image = "test_print.jpg"

        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°
        for ext in ['jpg', 'jpeg', 'png']:
            candidates = list(Path('.').glob(f'*.{ext}'))
            if candidates:
                test_image = str(candidates[0])
                break

    if not Path(test_image).exists():
        print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_image}")
        print("   ì‚¬ìš©ë²•: python test_troubleshoot.py <ì´ë¯¸ì§€_ê²½ë¡œ>")
        return

    symptom_text = "í˜„ì¬ì¦ìƒë­ì•¼? ì–´ë–»ê²Œí•´ì•¼í•´"

    results = await run_test(test_image, symptom_text)

    # ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥
    output_path = "troubleshoot_result.md"
    save_results_as_markdown(results, output_path)


if __name__ == "__main__":
    asyncio.run(main())
